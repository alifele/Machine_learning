{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Batch_Size.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alifele/Machine_learning/blob/master/TensorFlow/Batch_Size.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP4ONGNJO4N5",
        "colab_type": "text"
      },
      "source": [
        "#What exactly is batch size\n",
        "in this notebook i am going to disccus batch size. My source is https://www.youtube.com/watch?v=U4WB9p6ODjM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1mzi_HtPQ4u",
        "colab_type": "text"
      },
      "source": [
        "the batch size is the number of samples that will be passed through to the network at one time \n",
        "('batch' a.k.a 'min_batch').\n",
        "\n",
        "But what about Epoch?!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QPGQOTjP1Bg",
        "colab_type": "text"
      },
      "source": [
        "# batch $\\neq$ Epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD2z-WTNQMfg",
        "colab_type": "text"
      },
      "source": [
        "Note carefully that batch is not equal to Epoch\n",
        "\n",
        "let's think that we have 1000 pictures of dogs that we want to train out neural network with to identify the dog spices.\n",
        "let's think that we specify out batch size to ben 10.this means that ten pictures of dogs will be passed as a batch or group to the network.\n",
        "$\\frac{1000 images}{10} = 100-batches-per-epoch$ \\\\\n",
        "so Epoch means going through all of the data set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKkjRclDS3R1",
        "colab_type": "text"
      },
      "source": [
        "but why we do not pass the data one by one to the network?! \\\\\n",
        "we know that latger the batches Faster will be our training. But the quality of model will decrease if we increase the size of batches and will lower the models ability ot generelize the training (it will be over fitted). batch size is one of the hyperparameters that we should play with it inorder to get a better fit. \\\\\n",
        "on the other hand if we set the batch size a big number like 100, our computer will not have the adiquete power to proccess the 100  images in parallel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5KbU99gU4_E",
        "colab_type": "text"
      },
      "source": [
        "# How to bring it in our code?!\n",
        "in keras we can specify batch size like the following \\\\\n",
        "```\n",
        "model.fit(X_train, y_train, validation_data = valid_set, batch_size=10,\n",
        "epoch=20, shuffle=True, verbose=2)\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i7_b0hfO3xV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "|j"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tNPPuXtOyVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}